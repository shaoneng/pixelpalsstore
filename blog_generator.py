import os
import datetime
import json
import re
import sys
import time
import google.generativeai as genai
from bs4 import BeautifulSoup

# --- è¨­å®š ---
# å¾ç’°å¢ƒè®Šæ•¸è®€å– API é‡‘é‘°
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# --- æª”æ¡ˆèˆ‡è·¯å¾‘è¨­å®š ---
KEYWORDS_FILE = "keywords.txt"
PROMPT_TEMPLATE_FILE = "prompt_template.txt"
BLOG_LIST_PAGE = "Blog-List-Page.html"
BLOG_POST_TEMPLATE = "blog_post_template.html"
BLOG_OUTPUT_DIR = "blog"

# --- 1. Gemini API å‘¼å«æ¨¡çµ„ (å·²æ ¹æ“šæ‚¨çš„å»ºè­°ä¿®å¾©ä¸¦å¼·åŒ–) ---

def _strip_keys(obj):
    """é€’å½’å»æ‰ dict key å·¦å³ç©ºç™½ï¼Œè§£å†³ ' en' / '\nen ' è¿™ç±»æƒ…å†µã€‚"""
    if isinstance(obj, dict):
        return {k.strip(): _strip_keys(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [_strip_keys(i) for i in obj]
    return obj

def _extract_json(text: str) -> str | None:
    """
    å°è¯•åœ¨å¤§æ®µæ–‡æœ¬é‡ŒæŠ“ç¬¬ä¸€æ®µæˆ–å”¯ä¸€ä¸€æ®µ JSONã€‚
    å…è®¸ Gemini åœ¨ä¸¤è¾¹åŒ…å›´ markdown æ–‡å­—ã€‚
    """
    # ä½¿ç”¨ re.DOTALL (ç­‰åŒäº re.S) æ¥åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„ä»»æ„å­—ç¬¦
    match = re.search(r'\{[\s\S]*\}', text)
    return match.group(0) if match else None

def generate_blog_from_keyword(keyword: str, prompt_template: str) -> dict | None:
    max_retries, retry_delay = 3, 5
    for attempt in range(1, max_retries + 1):
        print(f"ğŸ¤– æ­£åœ¨å‘¼å« Gemini API... (ç¬¬ {attempt}/{max_retries} æ¬¡å˜—è©¦)")
        raw_text = f"Error: No valid response text was captured from the API on attempt {attempt}."
        try:
            # ç¢ºä¿ GEMINI_API_KEY å·²è¼‰å…¥
            if not GEMINI_API_KEY:
                raise ValueError("GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®šæˆ–ç‚ºç©ºã€‚")
            
            genai.configure(api_key=GEMINI_API_KEY)
            
            # (ä¿®æ­£) æ¨¡å‹åç¨±ä¿®æ­£ç‚ºæœ‰æ•ˆçš„ 'gemini-1.5-flash'
            model = genai.GenerativeModel(
                model_name="gemini-2.5-flash", 
                safety_settings={c: "BLOCK_NONE" for c in (
                    "HARM_CATEGORY_HARASSMENT",
                    "HARM_CATEGORY_HATE_SPEECH",
                    "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "HARM_CATEGORY_DANGEROUS_CONTENT",
                )}
            )

            prompt = prompt_template.format(keyword=keyword)
            response = model.generate_content(prompt)

            # 1. å…ˆæ‹¿åˆ°å­—ç¬¦ä¸²ï¼ˆå…¼å®¹ä¸åŒ SDK ç‰ˆæœ¬ï¼‰
            raw_text = getattr(response, "text", None)
            if raw_text is None and response.candidates:
                # fallback, æ–°ç‰ˆ SDK: response.candidates[0].content.parts[0].text
                raw_text = response.candidates[0].content.parts[0].text

            if not raw_text:
                 raise ValueError("å¾ API å›æ‡‰ä¸­ç„¡æ³•æå–ä»»ä½•æ–‡æœ¬å…§å®¹ã€‚")

            # 2. æŠŠçœŸæ­£çš„ JSON æ‘³å‡ºä¾†
            json_str = _extract_json(raw_text)
            if not json_str:
                raise ValueError("API å›å‚³æœªæª¢æ¸¬åˆ° JSON ç‰‡æ®µ")

            # 3. è§£æ + æ¸…æ´— key
            article_data = _strip_keys(json.loads(json_str))

            # 4. åŸºæœ¬çµæ§‹æ ¡é©—
            if "en" not in article_data or "postTitle" not in article_data.get("en", {}):
                raise KeyError("JSON ç¼ºå°‘ 'en.postTitle'ï¼Œè«‹æª¢æŸ¥ prompt æˆ– API å›å‚³")

            print("âœ… Gemini å·²æˆåŠŸç”Ÿæˆæ‰€æœ‰èªè¨€ç‰ˆæœ¬çš„æ–‡ç« å…§å®¹ï¼")
            return article_data

        except Exception as e:
            print(f"ğŸš¨ å˜—è©¦ {attempt} å¤±æ•—ï¼š{repr(e)}")
            print("==== API åŸå§‹å›æ‡‰å…§å®¹ (è‹¥æœ‰) ====")
            print(raw_text) # æ‰“å°æ•ç²åˆ°çš„åŸå§‹æ–‡æœ¬ä»¥ä¾›èª¿è©¦
            print("==============================")
            if attempt < max_retries:
                print(f"å°‡åœ¨ {retry_delay} ç§’å¾Œé‡è©¦â€¦\n")
                time.sleep(retry_delay)
            else:
                print("âŒ å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œå®£å‘Šå¤±æ•—ã€‚")
                return None

# --- 2. æª”æ¡ˆè™•ç†æ¨¡çµ„ (ç„¡è®Šå‹•) ---

def slugify(text: str) -> str:
    text = text.lower()
    text = re.sub(r'\s+', '-', text)
    text = re.sub(r'[^\w-]', '', text)
    return text

def create_new_blog_post(translations_data: dict):
    print(f"ğŸ“ æ­£åœ¨ '{BLOG_OUTPUT_DIR}/' è³‡æ–™å¤¾ä¸­å»ºç«‹æ–°çš„å¤šèªè¨€éƒ¨è½æ ¼æ–‡ç« æª”æ¡ˆ...")
    try:
        os.makedirs(BLOG_OUTPUT_DIR, exist_ok=True)
        with open(BLOG_POST_TEMPLATE, 'r', encoding='utf-8') as f:
            template_content = f.read()
        
        default_title = translations_data.get('en', {}).get('postTitle', 'untitled')
        filename = f"{slugify(default_title)}.html"
        translations_json_string = json.dumps(translations_data, ensure_ascii=False, indent=8)

        post_content = template_content.replace("{{TRANSLATIONS_JSON}}", translations_json_string)
        post_content = post_content.replace("{{POST_FILENAME}}", filename)
        post_content = post_content.replace("{{POST_DATE}}", datetime.date.today().strftime("%B %d, %Y"))
        post_content = post_content.replace("Post Title Placeholder", default_title)
        default_summary = translations_data.get('en', {}).get('postSummary', '')
        post_content = post_content.replace('<meta name="description" content="">', f'<meta name="description" content="{default_summary}">')
        
        output_path = os.path.join(BLOG_OUTPUT_DIR, filename)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(post_content)
        
        print(f"âœ… æ–°æ–‡ç« å·²å„²å­˜ç‚º: {output_path}")
        return filename
    except Exception as e:
        print(f"âŒ å»ºç«‹æ–‡ç« æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {repr(e)}")
        return None

def update_blog_list(translations_data: dict, filename: str):
    print(f"ğŸ”„ æ­£åœ¨æ›´æ–° '{BLOG_LIST_PAGE}'...")
    try:
        with open(BLOG_LIST_PAGE, 'r', encoding='utf-8') as f:
            soup = BeautifulSoup(f, 'html.parser')

        article_container = soup.find('div', class_='space-y-10')
        if not article_container:
            print(f"âŒ éŒ¯èª¤: åœ¨ '{BLOG_LIST_PAGE}' ä¸­æ‰¾ä¸åˆ° <div class='space-y-10'>ã€‚")
            return
            
        link_path = os.path.join(BLOG_OUTPUT_DIR, filename).replace("\\", "/")
        title = translations_data.get('en', {}).get('postTitle', 'Untitled')
        summary = translations_data.get('en', {}).get('postSummary', 'No summary available.')
        
        new_article_html = f"""
        <article>
            <h2 class="text-2xl sm:text-3xl font-bold text-apple-gray-800 mb-2">
                <a href="{link_path}" class="hover:text-apple-blue-500 transition-colors">{title}</a>
            </h2>
            <p class="text-sm text-apple-gray-500 mb-4">By AI Assistant | {datetime.date.today().strftime("%B %d, %Y")}</p>
            <p class="text-base leading-relaxed text-apple-gray-600">{summary}</p>
            <a href="{link_path}" class="inline-block mt-4 font-semibold text-apple-blue-500 hover:text-apple-blue-600">Read More &rarr;</a>
        </article>
        <hr class="border-apple-gray-200">
        """
        
        new_article_soup = BeautifulSoup(new_article_html, 'html.parser')
        article_container.insert(0, new_article_soup)

        with open(BLOG_LIST_PAGE, 'w', encoding='utf-8') as f:
            f.write(str(soup.prettify()))
        print(f"âœ… '{BLOG_LIST_PAGE}' å·²æˆåŠŸæ›´æ–°ï¼")
    except Exception as e:
        print(f"âŒ æ›´æ–°åˆ—è¡¨é é¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {repr(e)}")

# --- 3. ä¸»åŸ·è¡Œæµç¨‹ ---
def main():
    if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY_PLACEHOLDER":
        print("ğŸ”¥ğŸ”¥ğŸ”¥ éŒ¯èª¤: æ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸ `GEMINI_API_KEY` æˆ–é‡‘é‘°ä¸æ­£ç¢ºã€‚è«‹åœ¨ GitHub Secrets ä¸­è¨­å®šå®ƒã€‚")
        sys.exit(1)

    try:
        with open(KEYWORDS_FILE, 'r', encoding='utf-8') as f:
            keywords = [line.strip() for line in f if line.strip()]
        if not keywords:
            print(f"âœ… '{KEYWORDS_FILE}' æ˜¯ç©ºçš„ã€‚æ²’æœ‰éœ€è¦ç”Ÿæˆçš„æ–‡ç« ã€‚")
            return
    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°é—œéµè©æª”æ¡ˆ '{KEYWORDS_FILE}'ã€‚")
        sys.exit(1)

    try:
        with open(PROMPT_TEMPLATE_FILE, 'r', encoding='utf-8') as f:
            prompt_template = f.read()
    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ° Prompt æ¨¡æ¿æª”æ¡ˆ '{PROMPT_TEMPLATE_FILE}'ã€‚")
        sys.exit(1)
        
    keyword_to_process = keywords[0]
    print(f"--- é–‹å§‹è™•ç†é—œéµè©: '{keyword_to_process}' ---")
    
    generated_translations = generate_blog_from_keyword(keyword_to_process, prompt_template)
    
    if generated_translations:
        new_filename = create_new_blog_post(generated_translations)
        if new_filename:
            update_blog_list(generated_translations, new_filename)
            remaining_keywords = keywords[1:]
            with open(KEYWORDS_FILE, 'w', encoding='utf-8') as f:
                for kw in remaining_keywords:
                    f.write(kw + '\n')
            print(f"âœ… å·²æˆåŠŸè™•ç†å¹¶å¾ '{KEYWORDS_FILE}' ä¸­ç§»é™¤é—œéµè© '{keyword_to_process}'ã€‚")
            print(f"\nğŸ‰ æ­å–œï¼ä¸€å€‹æ–°çš„éƒ¨è½æ ¼æ–‡ç« å·²ç”Ÿæˆä¸¦æ›´æ–°ï¼")
        else:
            print("â— å› å»ºç«‹æª”æ¡ˆå¤±æ•—ï¼Œæµç¨‹å·²çµ‚æ­¢ã€‚é—œéµè©æœªå¾ä½‡åˆ—ä¸­ç§»é™¤ã€‚")
    else:
        print("â— å› å…§å®¹ç”Ÿæˆå¤±æ•—ï¼Œæµç¨‹å·²çµ‚æ­¢ã€‚é—œéµè©æœªå¾ä½‡åˆ—ä¸­ç§»é™¤ã€‚")

if __name__ == "__main__":
    main()
